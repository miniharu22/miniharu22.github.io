---
layout : single
title: "[Verilog] ReLU (w/Testbench)"
categories: 
  - Universal NPU-CNN Accelarator
toc: true
toc_sticky: true
use_math: true
---

ReLU 모듈 설계 및 검증용 테스트벤치 작성   

## 0. ReLU Module    

```verilog
module relu(in, en_relu, out);

    input [7:0] in;
    input en_relu;
    output [7:0] out;

    wire sel;

    assign sel = ~(en_relu & in[7]);

    assign out[7] = in[7] & sel;
    assign out[6] = in[6] & sel;
    assign out[5] = in[5] & sel;
    assign out[4] = in[4] & sel;
    assign out[3] = in[3] & sel;
    assign out[2] = in[2] & sel;
    assign out[1] = in[1] & sel;
    assign out[0] = in[0] & sel;

endmodule
```

<div align="left">
    <strong>RTL Schematic</strong>
  <img src="/assets/images/npu/106.png" width="70%" height="70%" alt=""/>
  <p><em></em></p>
</div>
{: .notice} 

- **ReLU (Rectified Linear Unit Module)**  
  - CNN이나 신경망 연산에서 활성화 함수로, 입력값이 음수일 경우 0으로 변환하고 양수는 그대로 출력  
  - 입력 신호에 따라 양수/음수 판단 후, 출력값을 결정  

  - **데이터 처리 과정**  
    - **1단계: 입력**  
      - 8비트 입력값: `in`  
      - 활성화 여부 제어 신호: `en_relu`  
      - 출력값: 8비트 `out`  

    - **2단계: 음수 검출 및 선택 신호 결정**  
      - `in[7]`을 통해 입력값이 음수인지 확인  
      - `en_relu`가 1이고 `in`이 음수일 경우, 출력값을 0으로 만들기 위한 선택 신호 `sel` 계산  
      - 선택 신호 계산식: `sel = ~(en_relu & in[7])`  
        - `en_relu=1`이고 `in`이 음수 → `sel=0`  
        - 그 외 경우 → `sel=1`  

    - **3단계: 출력 결정**  
      - `sel=1`일 경우: 입력값을 그대로 출력  
      - `sel=0`일 경우: 출력값을 0으로 설정  
      - 비트별로 `out[i] = in[i] & sel` 형태로 출력값 계산  
      - 최종적으로 8비트 출력 `out`을 생성  

    - **4단계: 최종 출력**  
      - 활성화 함수 ReLU 결과를 8비트 `out`으로 출력  
      - `en_relu=0`인 경우, 입력값을 그대로 통과시키며 ReLU 동작을 비활성화  

&nbsp;

## 1. ReLU Testbench   

```verilog
`timescale 1ns/10ps

module tb_relu;

	reg clk, reset;

    reg [8-1:0] mat_in [0:59];
	
	reg [8-1:0] in;
	wire [8-1:0] out;
	reg en, en_mp;
	wire out_en;

	relu r0(in, en, out);
	
	initial
	begin
		clk = 1;
		reset = 0;
		en = 0;

		#12 reset = 1;
		#8 en = 1;
		#100 en = 0;
		#100 en = 1;
		#100 en = 0;

	end
	
	always #5 clk = ~clk;
	
    integer i=0;

	initial
	begin		
		$readmemh("C://MY/Vivado/UniNPU/UniNPU.srcs/data/input_mp.txt", mat_in);
		begin
			#(20);
			for (i=0; i<60; i=i+1)
			begin
				in = mat_in[i];

				#(10);
			end
		end
	end

endmodule
```

<div align="left">
    <strong>Simulaton : ReLU Results</strong>
  <img src="/assets/images/npu/107.png" width="100%" height="100%" alt=""/>
  <p><em></em></p>
</div>
{: .notice} 

- **tb_relu (Testbench for ReLU Module)**  
  - ReLU 모듈의 동작을 검증하는 테스트벤치  
  - 외부 입력 데이터 파일에서 60개의 8비트 입력 데이터를 읽어와 ReLU 입력으로 주입  
  - 클럭 및 리셋을 생성하고, 활성화 신호(`en`)를 통해 ReLU 모듈의 동작을 확인   

  - **데이터 처리 과정**  
    - **1단계: 클럭 및 리셋 생성**  
      - `clk`: 10ns 주기로 토글되는 클럭 생성 (`always #5 clk = ~clk;`)  
      - `reset`: 초기에는 0, 12ns 이후 1로 설정  

    - **2단계: 입력 데이터 로드**  
      - `$readmemh`를 사용하여 외부 파일(`input_mp.txt`)에서 60개의 8비트 데이터를 읽어옴  
      - 읽은 데이터는 1차원 배열(`mat_in[0:59]`)에 저장  

    - **3단계: 활성화 신호 스케줄**  
      - `en` 신호를 활성화/비활성화하며 동작 제어  
        - 20ns에서 `en=1`  
        - 100ns마다 `en`을 1↔0으로 토글    

    - **4단계: 입력값 순차 적용**  
      - 초기화 후 20ns 지연  
      - 60개의 입력 데이터를 순차적으로 ReLU 모듈 입력(`in`)에 주입  
      - 각 입력값 간 간격은 10ns (`#(10)`)  

    - **5단계: 최종 출력**    
      - 입력값이 0 이하인 경우 `0`으로 출력    
      - 입력값이 0 이상인 경우 해당 값 그대로 출력    


&nbsp;


