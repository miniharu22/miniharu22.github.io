---
layout : single
title: "[Study] Convolution Architecture with Adder Tree"
categories: 
  - Universal NPU-CNN Accelarator
toc: true
toc_sticky: true
use_math: true
---

Adder Tree 방식을 응용한 Convolution layer 아키텍쳐에 대한 고찰   

## 0. Adder Tree Architecture   

&nbsp;

<div align="center">
  <img src="/assets/images/npu/7.png" width="60%" height="60%" alt=""/>
  <p><em>Adder Tree architecture</em></p>
</div>

&nbsp;

- **About architecture**   
  - adder tree 방식을 응용한 아키텍쳐로 기존의 adder tree 방식에 D_Flip Flop과 8bit adder를 1개씩 추가함   
  - adder tree의 최종값이 adder를 거쳐 FF에 저장되었다가 다음 cycle에 다시 adder로 보내져 해당 cycle의 adder tree의 최종값에 더해짐     
  - 무한정 더해지는 것은 아니며, Mux에 의해 FF에 저장된 값이 adder로 보내져서 더해지느냐 또는 그냥 0을 보내서 아무것도 더해지지 않게하냐가 결정됨    

&nbsp;

## 1. Architecture Mechanism   

&nbsp;

<div align="center">
  <img src="/assets/images/npu/2.jpg" width="60%" height="60%" alt=""/>
  <p><em>3x3 Adder Tree Example</em></p>
</div>

&nbsp;


- 일단 multiplier가 9개로 구성되어 있다고 가정   
- 그렇다면 1 cycle에 9개의 input과 9개의 weight의 곱셈의 합을 구할 수 있음   

&nbsp;

<div align="center">
  <img src="/assets/images/npu/1.jpg" width="60%" height="60%" alt=""/>
  <p><em>3x3 Filter Convolution</em></p>
</div>

&nbsp;

- **3x3 Filter 계산**
  - 만약 3x3 필터, 즉 9개의 input과 9개의 weight의 결과 값을 구해야 한다면 위 adder tree 구조에서는 1 사이클만에 수행 가능   
  - 그러므로 Mux는 0을 adder로 보내 adder tree의 값에 따로 다른 값을 더하지 않고 그대로 출력함   

&nbsp;

<div align="center">
  <img src="/assets/images/npu/3.jpg" width="60%" height="60%" alt=""/>
  <p><em>4x4 Filter Convolution</em></p>
</div>

&nbsp;

- **4x4 Filter 계산**   
  - 4x4 필터의 계산을 수행할려면, 16개의 input과 weight를 처리해야하므로 총 두 번의 cycle이 필요함   
  - 따라서 Mux는 0과 FF에 저장된 값을 벌갈아 보네 2사이클마다 유효한 값이 출력되도록 함   

&nbsp;

- **각 사이클 별 I/O**  
  - 각 사이클의 곱셈기의 Input과 FF의 I/O들을 나타내면 다음과 같음    
  - **1사이클**  
    - input0~7, weight0~7   
    - tree_out1 + 0 = tree_out1   
    - 0, 무효   
  - **2사이클**  
    - input8~15, weight8~15   
    - tree_out2 + tree_out1     
    - tree_out1, 무효   
  - **3사이클**  
    - input16~23, weight16~23  
    - tree_out3 + 0 = tree_out3   
    - tree_out2 + tree_out1, 유효    
  - **4사이클**  
    - input24~31, weight24~31   
    - tree_out4 + tree_out3   
    - tree_out3, 무효    
  - **5사이클**  
    - input32~39, weight0~7   
    - tree_out5 + 0 = tree_out5   
    - tree_out4 + tree_out3 , 유효   
  - 이처럼 1사이클 이후로 2사이클마다 유효한 값을 출력함    

&nbsp;

- **3x3x3 or 5x5**  
  - 비슷하게 3x3x3 혹은 5x5 필터의 경우, input과 weight 수가 19~27 사이이므로 Mux가 0 → FF → 0 → FF → FF를 반복해 출력하면 결과적으로 3사이클마다 유효한 값이 출력됨    
  - 이처럼 쓰이는 필터의 종류에 따라 덧셈을 몇 사이클 진행할지만 조정한다면 여러가지 필터에 대해서도 효율성을 유지하면서 연산을 수행할 수 있음    

&nbsp;

## 2. NPU Archiecture for Computing Efficiency   

&nbsp;

<div align="center">
  <img src="/assets/images/npu/8.png" width="60%" height="60%" alt=""/>
  <p><em></em></p>
</div>

&nbsp;

- **유효 곱셈기 이용률**   
  - 위 그래프는 weight의 개수에 따른 계산 효율, 즉 유효한 곱셈기의 이용률을 분석한 결과로 3x3 ~ 8x8, 3x3x3, 4x4x4 필터들에 대해서 도출함   
  - 결과를 보면 대부분의 모델에서 자주 쓰이는 3x3 필터에 대해 높은 효율을 보이고 그외의 경우에도 약 90% 정도의 효율을 유지하는 것을 확인했음   

&nbsp;

- **고찰1 : PE 병렬 배치**  
  - 이번 NPU는 총 8개의 PE를 배치할 예정인데 해당 유닛들은 같은 input을 공유하지만 서로 다른 weight 값을 입력받음, 즉 유닛들이 각각 다른 채널의 Conv를 수행한다고 할 수 있음    
  - 이는 input data가 DRAM에 저장되어 있다고 가정할 때 1개의 채널을 전부 수행하고 다른 채널을 시작하게 되면, 채널의 수 만큼 input을 또 불러와야하므로 비효율적이라고 생각함    
  - 여러개의 유닛을 배치해 Input을 동시에 공유시킨다면 Systolic array 방식처럼 각 유닛마다 따로 input을 저장하기 위한 레지스터를 추가할 필요 없이 여러 채널에 대한 연산을 동시에 수행할 수 있으므로 효율적이라고 판단함    
  - PE를 8개로 사용하는 이유는 대부분의 신경망에서 채널의 수가 8의 배수에 가까웠기 때문  

&nbsp;

- **고찰2 : 동작 방식**   
  - Conv를 어떻게 수행할 것인지는 Input과 weight를 사용자가 어떻게 주느냐에 따라 달라지는데, 예를 들어 8개의 채널에 대한 Conv를 모두 끝마치고 그 다음 8개 채널을 다시 Conv하고 싶다면, weight를 고정한 채로 input을 순서에 맞게 입력시켜주면 됨   
    - 반대로 input을 여러번 불러오는 것을 최소화하고 싶다면 input을 고정하고 weight를 변경하면 됨    
    - 즉, input을 고정하고 1사이클에서 0~7 채널의 필터의 weight를 입력하고 2사이클에서 8~15 채널의 weight를 입력하면 됨    
    - 이렇게 하면 같은 input을 사용하는 모든 채널을 계산하기 위해 input을 한번만 호출하면 됨   
  - 이후, maxpooling까지 한번에 수행하고 싶다면 maxpooling이 2x2 = 4개의 output을 필요로 하므로 그에 맞게 4종류의 input을 번갈아 입력하고 4사이클마다 weight를 바꿔주면 됨    

&nbsp;

**각 사이클에서의 Input/Output**   
(1사이클) (input set 0, channel 0~7) (output0 of channel 0~7)   
(2사이클) (input set 1, channel 0~7) (output1 of channel 0~7)   
(3사이클) (input set 2, channel 0~7) (output2 of channel 0~7)   
(4사이클) (input set 3, channel 0~7) (output3 of channel 0~7)   
-> maxpooling output of channel 0~7   
(5사이클) (input set 0, channel 8~15) (output0 of channel 8~15)   
(6사이클) (input set 1, channel 8~15) (output1 of channel 8~15)  
(7사이클) (input set 2, channel 8~15) (output2 of channel 8~15)  
(8사이클) (input set 3, channel 8~15) (output3 of channel 8~15)  
-> maxpooling output of channel 8~15    
{: .notice}   

&nbsp;

- **장단점 고찰**    
  - **장점**
    - 이런 식으로 input set0~3와 채널들의 weight가 캐시에 저장되어 있다면 DRAM을 여러번 참조할 필요가 없음    
    - 해당 방법은 input size, weight 개수, stride, 필터 개수 등 여러 요인에 상관 없이 계산을 수행할 수 있다고 예상됨    
  - **단점**
    - 다만, 구조상 곱셈기 -> 덧셈기로 이어지는 구간에서 상당히 긴 critical path가 생길 것으로 예상하는데 추가로 면적을 차지하는 pipelining을 피하기 위해서는 효율이 높은 곱셈기와 뎃섬기를 사용해야 한다는 기존의 adder tree 방식과 같은 단점이 존재함    

&nbsp;

