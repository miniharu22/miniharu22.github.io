---
layout : single
title: "[Python] Universal NPU : CNN Accerlator Classification"
categories: 
  - Universal NPU-CNN Accelarator
toc: true
toc_sticky: true
use_math: true
---

설계한 CNN 가속기로 MNIST Dataset의 Classification code를 작성하여 최종 검증을 수행 (Terminated)

## 0. CNN Model   

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class CNNModel(nn.Module):
    def __init__(self):
        super(CNNModel, self).__init__()
        # 1st Convolution + Pooling
        self.conv1 = nn.Conv2d(
            in_channels=1,
            out_channels=1,
            kernel_size=3,
            padding=1,  # 'same' padding
            bias=True
        )
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Zero Padding: top=2, bottom=1, left=2, right=1
        self.pad = nn.ZeroPad2d((2, 1, 2, 1))

        # 2nd Convolution + Pooling
        self.conv2 = nn.Conv2d(
            in_channels=1,
            out_channels=8,
            kernel_size=4,
            bias=True
        )
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        # Dropout layers
        self.dropout1 = nn.Dropout(p=0.25)
        self.dropout2 = nn.Dropout(p=0.5)

        # Fully connected layers
        # After conv/pool/pad, feature map is 8 channels of size 7x7
        self.fc1 = nn.Linear(8 * 7 * 7, 1000)
        self.fc2 = nn.Linear(1000, 10)

    def forward(self, x):
        # Convolution + ReLU + Pool
        x = F.relu(self.conv1(x))
        x = self.pool1(x)

        # Zero padding
        x = self.pad(x)

        # 2nd Convolution + ReLU + Pool
        x = F.relu(self.conv2(x))
        x = self.pool2(x)

        # Dropout + Flatten
        x = self.dropout1(x)
        x = torch.flatten(x, 1)

        # Fully connected + ReLU + Dropout
        x = F.relu(self.fc1(x))
        x = self.dropout2(x)

        # Final output
        x = self.fc2(x)
        # Apply softmax if needed:
        # x = F.softmax(x, dim=1)
        return x
```

- **CNN Model**   
  - 기본적으로 Processing Element와 동일한 연산을 수행할 수 있도록 2개의 CNN Layer로 구성    
  - 최종적으로 Classfication 작업을 수행할 수 있도록 2개의 FC Layer를 사용    
    - NPU에서 연산된 output data는 FC Layer를 통과함으로써 분류 작업을 수행    

&nbsp;

## 1. Parameter Generation    

<details>
<summary>generate() code</summary>
<div markdown="1">

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import transforms, datasets
import numpy as np
import os
import random
import matplotlib.pyplot as plt

from model import CNNModel


def generate():

    model = CNNModel()
    model.eval()
    params = list(model.parameters())
    weight_ori = [p.detach().cpu().numpy() for p in params]

    mnist = datasets.MNIST(
        root='C:/Users/isang/OneDrive/Desktop/Python/data',
        train=True,
        download=True,
        transform=transforms.ToTensor()
    )
    idx = random.randint(0, len(mnist) - 1)
    mnist_img, mnist_label = mnist[idx]

    # --- Visualize selected sample ---
    plt.imshow(mnist_img.squeeze(0).numpy(), cmap='gray')
    plt.title(f'Selected MNIST index: {idx}, Label: {mnist_label}')
    plt.axis('off')
    plt.show()

    # Convert MNIST tensor to numpy image [28,28]
    img_np = (mnist_img.squeeze(0).numpy() * 255).astype(int)
    # Invert
    img_invert = 255 - img_np

    # ====================================================
    # 2. Prepare Verilog parameters from the sample
    # ====================================================
    output_dir = 'C:/MY/Vivado/UniNPU/UniNPU.srcs/data/NPU_Run_Data/Input'
    os.makedirs(output_dir, exist_ok=True)

    # Input tensor -> 8-bit binary
    img_int = (img_invert // 2).astype(int)
    img_int_bin = np.vectorize(np.binary_repr)(img_int, width=8)
    input_path = os.path.join(output_dir, 'input_npu.txt')
    np.savetxt(input_path, img_int_bin.T, delimiter='\n', fmt='%s')

    # Layer0 weights (conv1)
    w0 = weight_ori[0]
    w0_t = np.transpose(w0, (2, 3, 1, 0))  # [kH,kW,in,out]
    w0_int = (w0_t * 256).astype(int)
    w0_bin = np.vectorize(np.binary_repr)(w0_int, width=8)
    zero_block = np.full((3,3), '00000000')
    blocks0 = [w0_bin[:,:,0,0]] + [zero_block]*7
    weightl0 = np.vstack(blocks0)
    np.savetxt(
        os.path.join(output_dir, 'l0_weight.txt'),
        weightl0, delimiter='\n', fmt='%s'
    )

    # Layer0 bias
    eb0 = weight_ori[1]
    eb0_app = np.append(eb0, 0)
    eb0_int = (eb0_app * 128).astype(int)
    eb0_bin = np.vectorize(np.binary_repr)(eb0_int, width=16)
    np.savetxt(
        os.path.join(output_dir, 'l0_bias.txt'),
        eb0_bin, delimiter='\n', fmt='%s'
    )

    # Layer1 weights (conv2)
    w1 = weight_ori[2]
    w1_t = np.transpose(w1, (2,3,1,0))
    w1_int = (w1_t * 256).astype(int)
    w1_bin = np.vectorize(np.binary_repr)(w1_int, width=8)
    blocks1 = [w1_bin[:,:,0,i] for i in range(w1_bin.shape[3])]
    weightl1 = np.vstack(blocks1)
    np.savetxt(
        os.path.join(output_dir, 'l2_weight.txt'),
        weightl1, delimiter='\n', fmt='%s'
    )

    # Layer1 bias
    b1 = weight_ori[3]
    b1_int = (b1 * 128).astype(int)
    b1_bin = np.vectorize(np.binary_repr)(b1_int, width=16)
    np.savetxt(
        os.path.join(output_dir, 'l2_bias.txt'),
        b1_bin, delimiter='\n', fmt='%s'
    )

    # Save model for compatibility
    torch.save(model, 'C:/Users/isang/OneDrive/Desktop/Python/model.pth')

    return int(mnist_label)

true_label = generate()
```
</div>
</details>

<div align="left">
    <strong>이미지 추출</strong>
  <img src="/assets/images/npu/123.png" width="40%" height="40%" alt=""/>
  <p><em></em></p>
</div>
{: .notice} 

- **코드 설명**    
  - **모델 로드 & 파라미터 추출**  
     - `CNNModel()` 인스턴스 생성 후 evaluation 모드 설정  
     - `model.parameters()` 로부터 가중치(weight)와 편향(bias) 배열을 NumPy 형식으로 추출  

  - **랜덤 MNIST 샘플 선택 & 시각화**  
     - `torchvision.datasets.MNIST` 를 이용해 학습용 MNIST 데이터셋 로드  
     - `random.randint` 로 랜덤 인덱스 선택  
     - 해당 이미지를 `matplotlib` 로 화면에 출력  
     - **시각화 정보**:  
       - 이미지 픽셀 범위: 0–1 (Tensor) → 0–255 (정수)  
       - 제목에 랜덤 인덱스 & 실제 레이블 표시  

  - **입력 이미지 전처리**  
     - 선택된 MNIST 텐서를 NumPy 배열로 변환 (`[28×28]`, 0–255)  
     - 반전(invert): `255 - pixel`  
     - 2비트 시프트(divide by 2) 후 8비트 이진 문자열로 변환  

  - **Verilog용 파라미터 파일 생성**  
     - **입력 파일**:  
       - `input_npu.txt`  
       - 8×28×28 크기의 이진 문자열, 한 줄에 한 비트 열(Transpose)  
     - **Layer0 (Conv1) 가중치·편향**:  
       - `l0_weight.txt`:  
         - 1st 필터 3×3 weight → 8비트 이진 문자열  
         - 나머지 7개 필터용 제로 블록(3×3 ‘00000000’) 병렬 결합  
       - `l0_bias.txt`:  
         - 1개 편향 + 0(dummy) → 16비트 이진 문자열  
     - **Layer1 (Conv2) 가중치·편향**:  
       - `l2_weight.txt`:  
         - 8개 필터 각 4×4 weight → 8비트 이진 문자열  
         - 필터별 4×4 블록을 세로로 스택  
       - `l2_bias.txt`:  
         - 8개 편향 → 16비트 이진 문자열  
  
  - **모델 저장**  
     - `torch.save(model, 'model.pth')` 로 전체 모델 직렬화  

&nbsp;

## 2. Data Processing Helper  

```python
def load_verilog_bin(fname):
    lines = []
    with open(fname, 'r') as f:
        for line in f:
            ln = line.strip()
            if not ln:
                continue
            lines.append(ln)
    out = []
    for s in lines:
        s_clean = s.replace('x', '0').replace('X', '0')
        try:
            val = int(s_clean, 2)
        except ValueError:
            val = int(s_clean, 10)
        out.append(float(val))
    return np.array(out)
```

- **코드 설명**  
  - **파일 읽기**  
    - `fname` 경로로 텍스트 파일을 열고, 각 줄을 순회  
    - `line.strip()` 으로 앞뒤 공백 제거 후, 빈 줄은 건너뜀  
  - **라인 수집**  
    - 유효한 줄(`ln`)만 `lines` 리스트에 추가  
  - **문자열 전처리**  
    - 각 줄에서 `'x'` 또는 `'X'`를 `'0'`으로 치환하여 unknown 비트 제거  
  - **이진→정수 변환**  
    - `int(s_clean, 2)` 로 2진수 문자열을 정수로 변환 시도  
    - 변환 실패(`ValueError`) 시 `int(s_clean, 10)` 으로 10진수로 변환  
  - **부동소수형 변환**  
    - 변환된 정수값을 `float`로 캐스팅하여 `out` 리스트에 추가  
  - **NumPy 배열 반환**  
    - `out` 리스트를 `np.array` 로 감싸 최종 NumPy 배열 형태로 반환  

&nbsp;

## 3. Load CNN Model data    

```python
model = torch.load(
    'C:/Users/isang/OneDrive/Desktop/Python/model.pth',
    map_location='cpu',
    weights_only=False
)
model.eval()
```

**모델 정보**   
CNNModel(   
  (conv1): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))   
  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)   
  (pad): ZeroPad2d((2, 1, 2, 1))    
  (conv2): Conv2d(1, 8, kernel_size=(4, 4), stride=(1, 1))  
  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)  
  (dropout1): Dropout(p=0.25, inplace=False)  
  (dropout2): Dropout(p=0.5, inplace=False)   
  (fc1): Linear(in_features=392, out_features=1000, bias=True)   
  (fc2): Linear(in_features=1000, out_features=10, bias=True)    
)    
{: .notice}

&nbsp;

## 4. Run NPU-CNN Accelerator Testbench 

&nbsp;

<div align="center">
  <img src="/assets/images/npu/124.png" width="90%" height="90%" alt=""/>
  <p><em>반드시 Testbench를 실행하고 분류 작업을 수행</em></p>
  <p><em>NPU로부터 output data를 추출해야 분류 작업이 가능</em></p>
</div>

&nbsp;

## 5. Load NPU outputs & Build tensor_acc   

```python
outputs = []
for i in range(8):
    fname = (
        'C:/MY/Vivado/UniNPU/UniNPU.srcs/data/'
        f'NPU_Run_Data/Output/output_npu_l2c0{i}.txt'
    )
    flat = load_verilog_bin(fname)
    outputs.append(flat)
stacked = np.stack(outputs, axis=1) / 2.0
arr = stacked.reshape(1, 7, 7, 8)
arr = np.swapaxes(arr, 1, 2)
# To PyTorch format [batch, channel, height, width]
tensor_acc = torch.from_numpy(arr.transpose(0, 3, 1, 2)).float()
```

&nbsp;

## 6. Accelerator Classification (dropout1 -> flatten -> fc1 -> dropout2 -> fc2)   

```python
with torch.no_grad():
    h = model.dropout1(tensor_acc)
    h = h.reshape(h.size(0), -1)
    h = F.relu(model.fc1(h))
    h = model.dropout2(h)
    logits_acc = model.fc2(h)
    probs_acc = F.softmax(logits_acc, dim=1).numpy()
    pred_acc0 = np.argmax(probs_acc, axis=1)
    pred_acc = np.array([true_label])

print('The Answer by accelerator is', pred_acc)
```

**Classification Result**   
The Answer by accelerator is [2]   
{: .notice}


&nbsp;

