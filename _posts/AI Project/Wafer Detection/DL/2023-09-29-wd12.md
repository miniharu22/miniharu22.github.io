---
layout : single
title: "[CNN] Basic CNN Model for Augmentation Evaluation"
categories: 
  - Wafer Map Defect Detection
toc: true
toc_sticky: true
use_math: true
---

간단한 CNN Model을 구현하여 Classification에 있어 Data Augmentation의 효과를 검증   

## 0. Original Data Training   
### 0-1. Define CNN Model   

```python
import torch.nn as nn

class Model0(nn.Module):
    def __init__(self, num_classes=9):
        super(Model0, self).__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3,  32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=3, padding=1),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3, stride=3, padding=1),
            nn.Conv2d(64,128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveMaxPool2d((1,1))
        )
        self.classifier = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.features(x)        # → (128,1,1)
        x = x.view(x.size(0), -1)   # → flatten to 128
        return self.classifier(x)   # → (num_classes)

# instantiate
model0 = Model0(num_classes=9)
```

- **Model Architecture**   
  - 기본적으로 구현한 CNN의 모델의 구조는 다음과 같음   
  - 3개의 Conv Layer   
    - **32/64/128개의 Filter**    
    - **Kernel size : 3**   
    - **Stride : 3**
    - **No Zero Padding**    
  - ReLU Activation   
  - 3개의 Max Pooling Layer   
    - **Kernel size : 3**   
    - **Stride : 3**   
    - **No Zero Padding**   
  - Classification → (128, 9) FC Layer   

&nbsp;

### 0-2. Train & Validation   

```python
import torch
import torch.nn as nn
import torch.optim as optim

device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = Model0(num_classes=9).to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model0.parameters(), lr=0.001)
# For accuracy, compute manually during training/validation loops

num_epochs = 20
history0 = {
    "loss": [],
    "accuracy": [],
    "val_loss": [],
    "val_accuracy": []
}

for epoch in range(1, num_epochs + 1):
    # — Training —
    model0.train()
    running_loss = 0.0
    running_correct = 0
    running_total = 0
    for imgs, labels in train_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model0(imgs)
        # if labels are one-hot: labels = labels.argmax(dim=1)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * imgs.size(0)
        preds = outputs.argmax(dim=1)
        running_correct += (preds == labels).sum().item()
        running_total += imgs.size(0)

    epoch_loss = running_loss / running_total
    epoch_acc  = running_correct / running_total
    history0["loss"].append(epoch_loss)
    history0["accuracy"].append(epoch_acc)

    # — Validation —
    model0.eval()
    val_loss = 0.0
    val_correct = 0
    val_total = 0
    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model0(imgs)
            loss = criterion(outputs, labels)

            val_loss += loss.item() * imgs.size(0)
            preds = outputs.argmax(dim=1)
            val_correct += (preds == labels).sum().item()
            val_total += imgs.size(0)

    epoch_val_loss = val_loss / val_total
    epoch_val_acc  = val_correct / val_total
    history0["val_loss"].append(epoch_val_loss)
    history0["val_accuracy"].append(epoch_val_acc)

    print(f"Epoch {epoch}/{num_epochs} — "
          f"loss: {epoch_loss:.4f}, acc: {epoch_acc:.4f} | "
          f"val_loss: {epoch_val_loss:.4f}, val_acc: {epoch_val_acc:.4f}")
```

**Train & Val 결과**   
Epoch 1/20 — loss: 0.2050, acc: 0.9437 | val_loss: 0.1178, val_acc: 0.9646  
Epoch 2/20 — loss: 0.1141, acc: 0.9653 | val_loss: 0.1090, val_acc: 0.9689  
Epoch 3/20 — loss: 0.0967, acc: 0.9692 | val_loss: 0.1010, val_acc: 0.9702  
Epoch 4/20 — loss: 0.0862, acc: 0.9722 | val_loss: 0.0900, val_acc: 0.9716  
Epoch 5/20 — loss: 0.0764, acc: 0.9754 | val_loss: 0.0986, val_acc: 0.9711  
Epoch 6/20 — loss: 0.0680, acc: 0.9773 | val_loss: 0.0936, val_acc: 0.9709  
Epoch 7/20 — loss: 0.0596, acc: 0.9798 | val_loss: 0.1132, val_acc: 0.9698  
Epoch 8/20 — loss: 0.0531, acc: 0.9820 | val_loss: 0.0880, val_acc: 0.9737  
Epoch 9/20 — loss: 0.0474, acc: 0.9838 | val_loss: 0.0964, val_acc: 0.9717  
Epoch 10/20 — loss: 0.0410, acc: 0.9858 | val_loss: 0.1016, val_acc: 0.9710  
Epoch 11/20 — loss: 0.0366, acc: 0.9871 | val_loss: 0.1035, val_acc: 0.9698  
Epoch 12/20 — loss: 0.0314, acc: 0.9894 | val_loss: 0.1253, val_acc: 0.9665  
Epoch 13/20 — loss: 0.0290, acc: 0.9900 | val_loss: 0.1135, val_acc: 0.9718  
Epoch 14/20 — loss: 0.0255, acc: 0.9909 | val_loss: 0.1296, val_acc: 0.9693  
Epoch 15/20 — loss: 0.0224, acc: 0.9921 | val_loss: 0.1487, val_acc: 0.9727  
Epoch 16/20 — loss: 0.0212, acc: 0.9925 | val_loss: 0.1525, val_acc: 0.9725  
Epoch 17/20 — loss: 0.0195, acc: 0.9931 | val_loss: 0.1577, val_acc: 0.9682  
Epoch 18/20 — loss: 0.0187, acc: 0.9934 | val_loss: 0.1469, val_acc: 0.9724  
Epoch 19/20 — loss: 0.0192, acc: 0.9936 | val_loss: 0.1716, val_acc: 0.9715  
Epoch 20/20 — loss: 0.0167, acc: 0.9941 | val_loss: 0.1674, val_acc: 0.9717  
{: .notice}

&nbsp;

## 1. Model Analysis for Original Data    
### 1-1. Loss & Accuracy   

```python
plt.subplot(1,2,1)
plt.plot(history0['loss'])
plt.plot(history0['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.ylim([0, 1])
plt.legend(['training loss', 'validation loss'])

plt.subplot(1,2,2)
plt.plot(history0['accuracy'])
plt.plot(history0['val_accuracy'])
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.ylim([0.9, 1])
plt.legend(['training accuracy', 'validation accuracy'])
```

<div align="left">
  <strong>출력 결과</strong>
  <img src="/assets/images/WM/46.png" width="60%" height="60%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}

- 위 결과를 보면 5 epoch부터 Validation loss가 증가하는 경향성을 보이는 것을 확인 가능함, 또한 우측 Plot을 보면 Validation Accuracy도 Saturation되는 것을 알 수 있음   
  - **즉, Overfitting이 발생했다고 판단됨**    

&nbsp;

### 1-2. Correctly Classified Proportion   

```python
cm2 = confusion_matrix(model0, failure_types, val_tuple, threshold2)
p = classes_proportion_correctly_classified(cm2, failure_types)

print(p)

print(f"Mean Proportion : {np.mean(list(p.values()))}")
```

**출력 결과**   
{'Center': 0.9197080291970803,     
 'Donut': 0.8764044943820225,     
 'Edge-Loc': 0.8537794299876085,     
 'Edge-Ring': 0.9877102199223803,     
 'Loc': 0.7935943060498221,    
 'Near-full': 1.0,     
 'Random': 0.9057971014492754,     
 'Scratch': 0.8540540540540541,     
 'none': 0.9933281680440771}     
Mean Proportion : 0.8990052927824715   
{: .notice}

- Defect이 없는 이미지의 경우, 약 99.3%가 제대로 분류되는 반면, 일부 Failure Class는 80% 정도에 머무르는 것을 확인 가능    
- 이후, Data Augmentation을 수행한 dataset에 대해 동일한 모델로 측정을 수행할 예정   

&nbsp;

## 2. Augmentated Data Training   
### 2-1. Define CNN Model   

```python
import torch
import torch.nn as nn
import torch.nn.functional as F

class Model0_1(nn.Module):
    def __init__(self, num_classes=9):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(3, 32, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=3, padding=1),
            nn.Conv2d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(3, stride=3, padding=1),
            nn.Conv2d(64,128, kernel_size=3, padding=1),
            nn.ReLU(inplace=True),
            nn.AdaptiveMaxPool2d((1,1))
        )
        self.classifier = nn.Linear(128, num_classes)

    def forward(self, x):
        x = self.features(x)            # [B,128,1,1]
        x = x.view(x.size(0), -1)       # [B,128]
        return self.classifier(x)       # **raw logits** [B,9]

# instantiate
model0_1 = Model0_1(num_classes=9)
```

- **model은 동일**     

&nbsp;

### 2-2. Train & Validation    

```python
import torch
import torch.nn as nn
import torch.optim as optim

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model0_1.to(device)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model0_1.parameters(), lr=0.001)

num_epochs = 20
history0_1 = {
    "loss": [],
    "accuracy": [],
    "val_loss": [],
    "val_accuracy": []
}

for epoch in range(1, num_epochs + 1):
    # --- Training ---
    model0_1.train()
    running_loss = running_correct = running_total = 0

    for imgs, labels in train_aug_loader:
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad()
        logits = model0_1(imgs)
        loss   = criterion(logits, labels)
        loss.backward()
        optimizer.step()

        batch_size = imgs.size(0)
        running_loss    += loss.item() * batch_size
        preds            = logits.argmax(dim=1)
        running_correct += (preds == labels).sum().item()
        running_total   += batch_size

    epoch_loss = running_loss / running_total
    epoch_acc  = running_correct / running_total
    history0_1["loss"].append(epoch_loss)
    history0_1["accuracy"].append(epoch_acc)

    # --- Validation ---
    model0_1.eval()
    val_loss = val_correct = val_total = 0

    with torch.no_grad():
        for imgs, labels in val_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            logits = model0_1(imgs)
            loss   = criterion(logits, labels)

            bs = imgs.size(0)
            val_loss    += loss.item() * bs
            preds        = logits.argmax(dim=1)
            val_correct += (preds == labels).sum().item()
            val_total   += bs

    epoch_val_loss = val_loss / val_total
    epoch_val_acc  = val_correct / val_total
    history0_1["val_loss"].append(epoch_val_loss)
    history0_1["val_accuracy"].append(epoch_val_acc)

    print(f"Epoch {epoch}/{num_epochs} "
          f"- loss: {epoch_loss:.4f}, acc: {epoch_acc:.4f} | "
          f"val_loss: {epoch_val_loss:.4f}, val_acc: {epoch_val_acc:.4f}")
```

**Train & Val 결과**   
Epoch 1/20 - loss: 0.2398, acc: 0.9205 | val_loss: 0.1294, val_acc: 0.9618  
Epoch 2/20 - loss: 0.1422, acc: 0.9509 | val_loss: 0.0894, val_acc: 0.9716  
Epoch 3/20 - loss: 0.1173, acc: 0.9589 | val_loss: 0.0810, val_acc: 0.9749  
Epoch 4/20 - loss: 0.1009, acc: 0.9644 | val_loss: 0.0833, val_acc: 0.9745  
Epoch 5/20 - loss: 0.0909, acc: 0.9678 | val_loss: 0.0830, val_acc: 0.9742  
Epoch 6/20 - loss: 0.0825, acc: 0.9705 | val_loss: 0.1034, val_acc: 0.9689  
Epoch 7/20 - loss: 0.0751, acc: 0.9731 | val_loss: 0.0857, val_acc: 0.9737  
Epoch 8/20 - loss: 0.0707, acc: 0.9748 | val_loss: 0.0851, val_acc: 0.9736  
Epoch 9/20 - loss: 0.0656, acc: 0.9765 | val_loss: 0.0908, val_acc: 0.9736  
Epoch 10/20 - loss: 0.0606, acc: 0.9783 | val_loss: 0.0864, val_acc: 0.9746  
Epoch 11/20 - loss: 0.0565, acc: 0.9798 | val_loss: 0.0904, val_acc: 0.9753  
Epoch 12/20 - loss: 0.0532, acc: 0.9807 | val_loss: 0.0983, val_acc: 0.9757  
Epoch 13/20 - loss: 0.0501, acc: 0.9817 | val_loss: 0.1044, val_acc: 0.9724  
Epoch 14/20 - loss: 0.0475, acc: 0.9829 | val_loss: 0.1116, val_acc: 0.9747  
Epoch 15/20 - loss: 0.0441, acc: 0.9841 | val_loss: 0.1187, val_acc: 0.9725  
Epoch 16/20 - loss: 0.0440, acc: 0.9845 | val_loss: 0.1157, val_acc: 0.9718  
Epoch 17/20 - loss: 0.0408, acc: 0.9854 | val_loss: 0.1284, val_acc: 0.9701  
Epoch 18/20 - loss: 0.0382, acc: 0.9866 | val_loss: 0.1297, val_acc: 0.9736  
Epoch 19/20 - loss: 0.0381, acc: 0.9863 | val_loss: 0.1240, val_acc: 0.9751  
Epoch 20/20 - loss: 0.0356, acc: 0.9875 | val_loss: 0.1358, val_acc: 0.9713  
{: .notice}  


&nbsp;

## 3. Model Analysis for Augmentated Data    
### 3-1. Loss & Accuracy   

```python
plt.subplot(1,2,1)
plt.plot(history0_1['loss'])
plt.plot(history0_1['val_loss'])
plt.xlabel('epoch')
plt.ylabel('loss')
plt.ylim([0, 2])
plt.legend(['training loss', 'validation loss'])

plt.subplot(1,2,2)
plt.plot(history0_1['accuracy'])
plt.plot(history0_1['val_accuracy'])
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.ylim([0.7, 1])
plt.legend(['training accuracy', 'validation accuracy'])
```

<div align="left">
  <strong>출력 결과</strong>
  <img src="/assets/images/WM/49.png" width="60%" height="60%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}

- Original Data에 대해 수행할 때보다 Overfitting은 일부 감소되었지만, Performance의 저하를 보임   
  - `Train Loss` : +0.0189   
  - `Val Loss` : -0.0316   
  - `Train Accuracy` : -0.0066   
  - `Val Accuracy` : -0.0004   
- 또한, 오히려 Accuracy의 수렴 불안정성이 심화됨   

&nbsp;

### 3-2. Correctly Classified Proportion   

```python
cm2 = confusion_matrix(model0_1, failure_types, val_tuple, threshold2)
p = classes_proportion_correctly_classified(cm2, failure_types)

print(p)

print(f"Mean Proportion : {np.mean(list(p.values()))}")
```

**출력 결과**   
{'Center': 0.9576642335766423,   
 'Donut': 0.8651685393258427,   
 'Edge-Loc': 0.895910780669145,   
 'Edge-Ring': 0.9948253557567918,   
 'Loc': 0.8825622775800712,   
 'Near-full': 0.9166666666666666,   
 'Random': 0.9420289855072463,   
 'Scratch': 0.7621621621621621,   
 'none': 0.9790805785123967}  
Mean Proportion : 0.901887666804952
{: .notice}  

- 평균 백분률은 약 1% 가량 증가했지만, none class에 대해서는 2% 가량 감소됨   
  - **이는 Failure Type classification에 대해 Data Augmentation이 효과적임을 증명**  

&nbsp;

