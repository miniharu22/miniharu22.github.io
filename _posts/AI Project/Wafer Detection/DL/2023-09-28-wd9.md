---
layout : single
title: "[CNN] Rotation & Flip + Process Summary"
categories: 
  - Wafer Map Defect Detection
toc: true
toc_sticky: true
use_math: true
---

전체 Train dataset에 대해서 이미지 회전과 반전을 수행 + 최종적으로 구축한 Train Set을 분석   

## 0. Data Augmentation : Rotation & Flip   
### 0-1. Load Resized Train Set   

```python
import json
import pandas as pd
import gc

with open('C://Users/isang/OneDrive/Desktop/WM/data/WM811K_train_padded_resized_augmented.json', 'r') as f:
  data_aug = json.load(f)

cols = data_aug['columns']

dict_ = dict()

for col in cols:
  dict_[col] = list()

for i in range(len(cols)):
  for j in range(len(data_aug['data'])):
    if i == 0:
      dict_[cols[i]].append(data_aug['data'][j][i])
    elif i == 1:
      dict_[cols[i]].append(data_aug['data'][j][i])

data_aug = pd.DataFrame(dict_)

classes = ["Center", "Donut", "Edge-Loc", "Edge-Ring", "Loc", "Near-full", "Random", "Scratch", "none"]
training_aug = [0] * 9

for i in range(9):
  training_aug[i] = data_aug[data_aug['failureType'] == classes[i]]
  training_aug[i] = training_aug[i].reset_index(drop = True)

del data_aug
del dict_

training_aug[1].head()
```

<div align="left">
  <strong>출력 결과</strong>
  <img src="/assets/images/WM/42.png" width="60%" height="60%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}

&nbsp;

### 0-2. Image Rotation & Flipping   

```python
import copy
from PIL import Image
import numpy as np

for i in range(len(training_aug) - 1):
  print(classes[i])
  for j in range(len(training_aug[i]['waferMap'])):
    img = copy.deepcopy(Image.fromarray(np.array(training_aug[i]['waferMap'][j], dtype = np.uint8)))
    horiz_img = img.transpose(method = Image.FLIP_LEFT_RIGHT)
    vert_img = img.transpose(method = Image.FLIP_TOP_BOTTOM)
    rotated_img_1 = img.transpose(method = Image.ROTATE_90)
    rotated_img_2 = img.transpose(method = Image.ROTATE_270)
    training_aug[i].loc[training_aug[i].shape[0]] = [horiz_img, classes[i]]
    training_aug[i].loc[training_aug[i].shape[0]] = [vert_img, classes[i]]
    training_aug[i].loc[training_aug[i].shape[0]] = [rotated_img_1, classes[i]]
    training_aug[i].loc[training_aug[i].shape[0]] = [rotated_img_2, classes[i]]
```

**출력 결과**     
Center  
Donut  
Edge-Loc  
Edge-Ring  
Loc  
Near-full  
Random  
Scratch  
{: .notice}

- 전체 Failure Type Class에 속한 이미지에 대해 수평/수직 반전과 90°/270° 회전을 수행   
- **데이터 증강(Data Augmentation)**을 수행하는 이유 등 자세한 설명은 [[Generalization] Data Augmentation](https://miniharu22.github.io/deep%20learning%20basic/d20/)을 참고    

&nbsp;

### 0-3. Add rotated & flipped Images to Train Set   

```python
for i in range(len(training_aug)):
  print(classes[i])
  for j in range(len(training_aug[i]['waferMap'])):
    training_aug[i]['waferMap'][j] = np.array(training_aug[i]['waferMap'][j])
```

**출력 결과**  
Donut  
Edge-Loc  
Edge-Ring  
Loc  
Near-full  
Random  
Scratch  
none  
{: .notice}   

&nbsp;

### 0-4. Store Final Train Dataset   

```python
final_train_data = pd.concat([training_aug[0],training_aug[1],training_aug[2],
                              training_aug[3],training_aug[4],training_aug[5],
                              training_aug[6],training_aug[7],training_aug[8]])
del training_aug
gc.collect()
training_aug = pd.DataFrame()
gc.collect()

final_train_data['failureType'] = list(map(lambda x: str(x), final_train_data['failureType']))

parsed = json.loads(final_train_data.to_json(orient = "split"))
del final_train_data
gc.collect()
final_train_data = pd.DataFrame()
gc.collect()

with open('C://Users/isang/OneDrive/Desktop/WM/data/WM811K_final_train.json','w') as f:
    json.dump(parsed, f)
del parsed
```

&nbsp;

## 1. Process Summary   
### 1-1. Load Final Train Set   

```python
with open('C://Users/isang/OneDrive/Desktop/WM/data/WM811K_final_train.json', 'r') as f:
  data = json.load(f)

cols = data['columns']

dict_ = dict()

for col in cols:
  dict_[col] = list()

for i in range(len(cols)):
  for j in range(len(data['data'])):
    if i == 0:
      dict_[cols[i]].append(data['data'][j][i])
    elif i == 1:
      dict_[cols[i]].append(data['data'][j][i])

data = pd.DataFrame(dict_)

failure_types = list(pd.unique(data['failureType']))

print(failure_types)

data.head()
```

<div align="left">
  <strong>출력 결과</strong><br>
  ['Center', 'Donut', 'Edge-Loc', 'Edge-Ring', 'Loc', 'Near-full', 'Random', 'Scratch', 'none']<br>
  <img src="/assets/images/WM/43.png" width="60%" height="60%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}


&nbsp;

### 1-2. Check Number of Images & Proportion of classes   

```python
types_image_number = list(map(lambda x: (data['failureType']==x).sum(), failure_types))

types_image_proportion = list(map(lambda x: round(x/data.shape[0],3), types_image_number))

print(types_image_number)
print(types_image_proportion)
```

**출력 결과**   
[17115, 15000, 20170, 38640, 15000, 15000, 15000, 15000, 116022]   
[0.064, 0.056, 0.076, 0.145, 0.056, 0.056, 0.056, 0.056, 0.435]   
{: .notice}

&nbsp;

### 1-3. Visualization for N/% of Images per class   

```python
import matplotlib.pyplot as plt

plt.subplot(2,1,1)
plt.barh(failure_types, types_image_number)
plt.xlabel('number of images per class')

plt.subplot(2,1,2)
plt.barh(failure_types, types_image_proportion)
plt.xlabel('% of images per class')

plt.tight_layout()
```

<div align="left">
  <strong>출력 결과</strong>
  <img src="/assets/images/WM/44.png" width="70%" height="70%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}

- `none`을 제외한 Failute Type class들의 전체 이미지 수가 거의 균일하게 맞춰져 있음을 확인 가능    
- Classification을 수행하는 데 있어 데이터 간의 불균형은 해소했다고 판단함   

&nbsp;

### 1-4. Visualization for Fail vs none   

```python
number_failure_images = sum(types_image_number[:8])
number_ok_images = types_image_number[8]

plt.bar(['with_failure','none'],[number_failure_images,number_ok_images])
```

<div align="left">
  <strong>출력 결과</strong>
  <img src="/assets/images/WM/45.png" width="70%" height="70%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}

- 또한 Failure Type class의 모든 이미지의 개수합과 none class의 이미지의 수도 어느 정도 균형을 찾았음을 확인 가능   

&nbsp;

