---
layout : single
title: "[CNN] Dataset Split & Data Augmentation"
categories: 
  - Wafer Map Defect Detection
toc: true
toc_sticky: true
use_math: true
---


## 0. Dataset Split to Train & Test Set  
### 0-1. Remove unneccessary columns from dataset   

```python
with open('C://Users/isang/OneDrive/Desktop/WM/data/WM811K_clean.json', 'r') as f:
  data = json.load(f)

cols = data['columns']
dict_ = dict()

for col in cols:
  dict_[col] = list()

for i in range(len(cols)):
  for j in range(len(data['data'])):
    if i == 6:
      dict_[cols[i]].append(tuple(data['data'][j][i]))
    elif i == 5:
      dict_[cols[i]].append(np.array(data['data'][j][i]))
    else:
      dict_[cols[i]].append(data['data'][j][i])

data = pd.DataFrame(dict_)

data.drop(['dieSize', 'lotName', 'waferIndex', 'trainTestLabel', 'shape'], axis = 1, inplace = True)
data.head()
```

<div align="left">
  <strong>출력 결과</strong>
  <img src="/assets/images/WM/30.png" width="80%" height="80%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}

- 오로지 Failure Type class에 대해서만 이미지 분류를 진행할 것이기 때문에 이외에 불필요한 데이터는 제거    

&nbsp;

### 0-2. Dataset Split    

```python
classes = ["Center", "Donut", "Edge-Loc", "Edge-Ring", "Loc", "Near-full", "Random", "Scratch", "none"]
training = [0] * 9
test = [0] * 9

for i in range(9):
  training[i] = data[data['failureType'] == classes[i]]
  test[i] = training[i].sample(frac = 0.2)
  training[i] = training[i].drop(test[i].index)

print(sum(len(i) for i in training))
print(sum(len(i) for i in test))

training[0].head()
```

<div align="left">
  <strong>출력 결과</strong><br>
  136196<br> 
  34050
  <img src="/assets/images/WM/31.png" width="80%" height="80%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}

- 전체 Dataset에서 80:20의 비율로 Train Set과 Test Set을 분리함    


&nbsp;

### 0-3. Reset Index   

```python
# Reset Index
classes = failure_types

for i in range(len(training)):
  training[i] =  training[i].reset_index(drop = True)
  test[i] =  test[i].reset_index(drop = True)

training[0].head()
```

<div align="left">
  <strong>출력 결과</strong>
  <img src="/assets/images/WM/32.png" width="80%" height="80%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}

&nbsp;

## 1. Data Augmentation : Resizing    
### 1-1. Image Padding   

```python
import math
import copy

# Padding Function   
def apply_padding(a):
  dim1, dim2 = a.shape
  pad11 = 0
  pad12 = 0
  pad21 = 0
  pad22 = 0
  if(dim1 < 53):
    pad11 = int((53 - dim1)/2)
    pad12 = 53 - dim1 - pad11
  if(dim2 < 52):
    pad21 = int((52 - dim2)/2)
    pad22 = 52 - dim2 - pad21
  if(dim1 > 53):
    pad11 = int((math.ceil(dim1/53) * 53 - dim1)/2)
    pad12 = math.ceil(dim1/53) * 53 - dim1 - pad11
  if(dim2 > 52):
    pad21 = int((math.ceil(dim2/52) * 52 - dim2)/2)
    pad22 = math.ceil(dim2/52) * 52 - dim2 - pad21

  return np.pad(a, ((pad11,pad12),(pad21,pad22)), 'constant', constant_values = ((0,0),(0,0)))

# Train Set Padding   
training_padded = copy.deepcopy(training)

for i in range(len(training_padded)):
  for j in range(len(training_padded[i]['waferMap'])):
    if (j % 500 == 0):
      print(i, j)
    training_padded[i]['waferMap'][j] = np.array(training_padded[i]['waferMap'][j])
    training_padded[i]['waferMap'][j] = apply_padding(training_padded[i]['waferMap'][j])

# Test Set Padding   
test_padded = copy.deepcopy(test)

for i in range(len(test_padded)):
  for j in range(len(test_padded[i]['waferMap'])):
    if (j % 500 == 0):
      print(i, j)
    test_padded[i]['waferMap'][j] = np.array(test_padded[i]['waferMap'][j])
    test_padded[i]['waferMap'][j] = apply_padding(test_padded[i]['waferMap'][j])
```

- Data Augmentation을 본격적으로 수행하기 전에 가장 먼저 이미지의 사이즈를 동일하게 규격화시켜야 함    
- 이를 위해 이미지에 **Background Pixel을 추가하는 Padding 함수**를 정의하여 Train Set과 Test Set 각각에 수행     

&nbsp;

### 1-2. Image Resizing   

```python
import copy
import numpy as np
import torch
import torch.nn.functional as F

training_padded_resize = copy.deepcopy(training_padded)

for i, subgroup in enumerate(training_padded_resize):
    wafer_maps = subgroup['waferMap']
    for j, img_np in enumerate(wafer_maps):
        if j % 500 == 0:
            print(i, j)
        img_t = torch.from_numpy(img_np.astype(np.float32)).unsqueeze(0).unsqueeze(0)
        resized_t = F.interpolate(img_t, size=(53, 52), mode='nearest')
        resized_np = resized_t.squeeze().numpy().astype(int)
        training_padded_resize[i]['waferMap'][j] = resized_np

test_padded_resize = copy.deepcopy(test_padded)

for i, subgroup in enumerate(test_padded_resize):
    wafer_maps = subgroup['waferMap']
    for j, img_np in enumerate(wafer_maps):
        if j % 500 == 0:
            print(i, j)
        img_t = torch.from_numpy(img_np.astype(np.float32)).unsqueeze(0).unsqueeze(0)
        resized_t = F.interpolate(img_t, size=(53, 52), mode='nearest')
        resized_np = resized_t.squeeze().numpy().astype(int)
        test_padded_resize[i]['waferMap'][j] = resized_np

for i in range(9):
  print(np.unique(list(map(lambda x: x.shape, training_padded_resize[i]['waferMap']))))


for i in range(12):
  plt.subplot(3,4,i+1)
  plt.imshow(training_padded_resize[0]['waferMap'][i])
  plt.xticks([])
  plt.yticks([])

plt.tight_layout()
```

<div align="left">
  <strong>출력 결과</strong><br>
  [52 53]<br>
  [52 53]<br>
  [52 53]<br>
  [52 53]<br>
  [52 53]<br>
  [52 53]<br>
  [52 53]<br>
  [52 53]<br>  
  [52 53]<br>  
  <img src="/assets/images/WM/33.png" width="80%" height="80%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}

- Train Set과 Test Set의 모든 이미지에 대해 (52,53)의 크기로 동일하게 규격화를 진행   
  - **그 결과, 모든 이미지는 중심값인 (53,52)로 크기가 규격화되는 동시에 원본의 이미지를 그대로 보존할 수 있음**   
- 일부 이미지를 size와 함께 출력한 결과, Wafer의 size에는 일부 차이가 있더라도 모든 이미지가 동일한 크기로 맞춰져 있음을 확인   

&nbsp;

### 1-3. Store Dataset    

```python
training_preprocessed = pd.concat([training_padded_resize[0],training_padded_resize[1],training_padded_resize[2],
                                   training_padded_resize[3],training_padded_resize[4],training_padded_resize[5],
                                   training_padded_resize[6],training_padded_resize[7],training_padded_resize[8]])
del training_padded_resize

training_preprocessed['failureType'] = list(map(lambda x: str(x), training_preprocessed['failureType']))

parsed = json.loads(training_preprocessed.to_json(orient = "split"))
del training_preprocessed

with open('C://Users/isang/OneDrive/Desktop/WM/data/WM811K_train_padded_resized_not_augmented.json','w') as f:
    json.dump(parsed, f)
del parsed

test_preprocessed = pd.concat([test_padded_resize[0],test_padded_resize[1],test_padded_resize[2],
                               test_padded_resize[3],test_padded_resize[4],test_padded_resize[5],
                               test_padded_resize[6],test_padded_resize[7],test_padded_resize[8]])
del test_padded_resize

test_preprocessed['failureType'] = list(map(lambda x: str(x), test_preprocessed['failureType']))

parsed = json.loads(test_preprocessed.to_json(orient = "split"))
del test_preprocessed

with open('C://Users/isang/OneDrive/Desktop/WM/data/WM811K_test_padded_resized_not_augmented.json','w') as f:
    json.dump(parsed, f)
del parsed
```

- Padding과 Resizing이 끝난 각각의 Dataset은 `.josn` 포맷의 파일로 저장    

&nbsp;

