---
layout : single
title: "[PTQ] Model Benchmark & Accuracy Test"
categories: 
  - Post Training Quantization SAM
toc: true
toc_sticky: true
use_math: true
---

Pytorch 기반의 SAM 모델을 TensorRT FP32와 FP16 포멧으로 변환 + 벤치마크 및 Acc 측정   

## 0. Environment Setting

```bash
chmod +x launch.sh

./launch.sh -b # Docker Image Build
./launch.sh -r # Docker Image Run
```

<div align="left">
  <strong>Docker Image</strong>
  <img src="/assets/images/sam/35.png" width="80%" height="80%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}

- **주의 사항**   
  - Docker 환경은 NVIDIA 기반의 GPU 환경에서 구축되어야 함   
  - 위 명령어는 bash 명령어를 지원하는 shell에서 실행해야 함 
    - GPU를 VScode에서 ssh를 통해 연결했다면, git-bash를 통해 실행이 가능    

&nbsp;

## 1. Model Conversion to FP32/FP16   

```bash
python main.py export --model_path pth_model/sam_vit_b_01ec64.pth --model_precision fp32
python main.py export --model_path pth_model/sam_vit_b_01ec64.pth --model_precision fp16
python main.py export --model_path pth_model/sam_vit_b_01ec64.pth --model_precision both

python main.py export --model_path pth_model/sam_vit_h_4b8939.pth --model_precision fp32
python main.py export --model_path pth_model/sam_vit_h_4b8939.pth --model_precision fp16
python main.py export --model_path pth_model/sam_vit_h_4b8939.pth --model_precision both

python main.py export --model_path pth_model/sam_vit_l_0b3195.pth --model_precision fp32
python main.py export --model_path pth_model/sam_vit_l_0b3195.pth --model_precision fp16
python main.py export --model_path pth_model/sam_vit_l_0b3195.pth --model_precision both
```

&nbsp;

## 2. Model Inference   

```bash
# vit_b & vit_l
python main.py infer --pth_path pth_model/sam_vit_b_01ec64.pth 
                     --model_1 exported_models/vit_b/model_fp32.engine 
                     --img_path images/original_image.jpg
# vit_h
python main.py infer --pth_path pth_model/sam_vit_h_4b8939.pth 
                     --model_1 exported_models/vit_h/model_fp32_1.engine 
                     --model_2 exported_models/vit_h/model_fp32_2.engine 
                     --img_path images/original_image.jpg
```

<div align="left">
  <strong>Original Image</strong>
  <img src="/assets/images/sam/1.jpg" width="50%" height="50%" alt=""/>
  <p><em></em></p>
</div>
{: .notice}

<div style="text-align: left;">
  <p><strong>vit_b mask predict</strong></p>
  <div style="display: flex; justify-content: center; gap: 10px;">
    <img src="/assets/images/sam/vit_b_Mask_Original.png" alt="Original vit_b" width="30%" />
    <img src="/assets/images/sam/vit_b_Mask_TensorRT.png" alt="TensorRT FP32 vit_b" width="30%" /> 
    <img src="/assets/images/sam/vit_b_Mask_TensorRT_FP16.png" alt="TensorRT FP16 vit_b" width="30%" />
  </div>
</div>
{: .notice}


<div style="text-align: left;">
  <p><strong>vit_l mask predict</strong></p>
  <div style="display: flex; justify-content: center; gap: 10px;">
    <img src="/assets/images/sam/vit_l_Mask_Original.png" alt="Original vit_l" width="30%" />
    <img src="/assets/images/sam/vit_l_Mask_TensorRT.png" alt="TensorRT FP32 vit_l" width="30%" /> 
    <img src="/assets/images/sam/vit_l_Mask_TensorRT_FP16.png" alt="TensorRT FP16 vit_l" width="30%" />
  </div>
</div>
{: .notice}

<div style="text-align: left;">
  <p><strong>vit_h mask predict</strong></p>
  <div style="display: flex; justify-content: center; gap: 10px;">
    <img src="/assets/images/sam/vit_h_Mask_Original.png" alt="Original vit_h" width="30%" />
    <img src="/assets/images/sam/vit_h_Mask_TensorRT.png" alt="TensorRT FP32 vit_h" width="30%" />
    <img src="/assets/images/sam/vit_h_Mask_TensorRT_FP16.png" alt="TensorRT FP16 vit_h" width="30%" />
  </div>
</div>
{: .notice}

&nbsp;

## 3. Model Accuracy (IOU) Test   

```bash
python main.py accuracy --image_dir test_images 
                        --model_type vit_b 
                        --sam_checkpoint pth_model/sam_vit_b_01ec64.pth  

python main.py accuracy --image_dir test_images 
                        --model_type vit_l
                        --sam_checkpoint pth_model/sam_vit_l_0b3195.pth

python main.py accuracy --image_dir test_images 
                        --model_type vit_h 
                        --sam_checkpoint pth_model/sam_vit_h_4b8939.pth
```

<div style="border: 1px solid #ccc; padding: 1em; background-color: #f9f9f9;">
  <strong>Accuracy (IOU) Result for FP32/FP16 models</strong>
  <br>
  <table>
    <thead>
      <tr>
        <th>Model</th>
        <th>Minimum IOU</th>
        <th>Mean IOU</th>
      </tr>
    </thead>
    <tbody>
      <tr><td>vit_b FP32</td><td>0.9986</td><td>0.9997</td></tr>
      <tr><td>vit_b FP16</td><td>0.9931</td><td>0.9986</td></tr>
      <tr><td>vit_l FP32</td><td>0.9983</td><td>0.9996</td></tr>
      <tr><td>vit_l FP16</td><td>0.9958</td><td>0.9987</td></tr>
      <tr><td>vit_h FP32</td><td>0.9982</td><td>0.9997</td></tr>
      <tr><td>vit_h FP16</td><td>0.9911</td><td>0.9983</td></tr>
    </tbody>
  </table>
</div>

