---
layout : single
title: "[VGGNet] VGGNet-19 Paper Review"
categories: 
  - Classification Model 
toc: true
toc_sticky: true
use_math: true
---

Very Deep Convolutional Networks for large-scale image recognition

[참고 논문 링크](https://arxiv.org/abs/1409.1556)  

- September 4 2014 
- [Karen Simonyan](https://arxiv.org/search/cs?searchtype=author&query=Simonyan,+K), [Andrew Zisserman](https://arxiv.org/search/cs?searchtype=author&query=Zisserman,+A)    

## 0. About VGGNet    

&nbsp;

- **기존 모델들의 한계**   
  - 모델의 깊이가 깊지 않기 때문에 feature들의 특징을 모두 담기 힘듦   
  - 더 정교한 feature map들을 추출하기 위해 kernel size를 키우거나 Stride를 작게 하는 방식을 선택    
    - 이는 모델의 성능은 향상시키지만, 학습시킬 파라미터의 양과 연산량이 많음   

&nbsp;

- **VGGNet의 장점**   
  - 모델의 kernel size를 3x3으로 설정하여 학습시킬 파라미터의 양을 줄임   
  - 파라미터의 양이 줄어들면서 상대적으로 깊게 Layer들을 쌓을 수 있음    

&nbsp;

## 1. 3x3 Convolution    

&nbsp;

- **3x3 Conv를 쓰는 이유**   
  - 5x5 Conv layer를 한번 쓰는 것과 3x3 Conv layer를 두번 쌓는 것은 동일하며, 7x7 Conv Layer는 3x3 Conv layer를 세번 쌓은 것과 동일함    
  - 그럼에도 3x3 Conv layer를 여러 번 쓰는 방식을 채택한 것은 다음과 같음   
    - 7x7 Conv layer를 한번 사용하면 비선형 변환을 한번 하게 되지만, 3개의 3x3 Conv layer를 사용하면, 세번의 비선형 변환이 가능함    
    - Conv layer를 지난 후의 채널 수를 $$C$$ 라고 정의할 때, 3개의 3x3 Conv Layer의 파라미터 수는 $$3(3^2C^2)=27C^2$$, 1개의 7x7 Conv Layer의 파라미터 수는 $$7^2C^2=49C^2$$   
      - **즉, 학습해야 할 파라미터 수가 확연히 줄어듦**    

&nbsp;

## 2. VGGNet Architecture    

&nbsp;

<div align="center">
  <img src="/assets/images/Net/25.png" width="70%" height="70%" alt=""/>
  <p><em></em></p>
</div>

&nbsp;

- **Conv Layer**   
  - 3x3 size kernel을 이용해 Conv 연산을 수행   
  - 이때, stride는 1이며 입력에 대해 zero-padding을 추가    

&nbsp;

- **Spatial Pooling**   
  - Pooling layer는 일부 Conv layer 뒤에 적용    
  - kernel size는 2x2이며, stride는 2로 설정하여 Max pooling 연산을 수행   

&nbsp;

- **FC Layer**   
  - 마지막 Conv layer 뒤에 3개의 FC Layer를 적용    
  - 처음 2개의 FC layer는 4096의 채널을 보유, 마지막 FC layer는 1000개의 class에 대해서 1000개의 채널과 함께 Softmax 연산을 수행    

&nbsp;

## 3. VS GoogLeNet   

&nbsp;

- **GooLeNet과의 차이점**   
  - 모델의 깊이가 깊어질수록 성능이 좋아진다는 것은 이미 증명된 사항히지만, GooLeNet은 22개의 layer에 대해 3x3, 1x1, 5x5 Conv layer를 모두 골고루 사용   
  - 다만, GooLeNet은 VGGNet 구조보다 복잡하면서도 첫번째 layer를 지난 뒤의 이미지 size가 너무 많이 감소된다는 단점이 존재   

&nbsp;

