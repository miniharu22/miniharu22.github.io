---
layout : single
title: "[LeNet] LeNet-5 Implementation"
categories: 
  - Classification Model 
toc: true
toc_sticky: true
use_math: true
---

LeNet-5 논문 구현   

[참고 논문 링크](https://ieeexplore.ieee.org/document/726791)  

- August 4 2002
- [Y. Lecun](https://ieeexplore.ieee.org/author/37282875900), [Léon Bottou](https://ieeexplore.ieee.org/author/37282877000), [Yoshua Bengio](https://ieeexplore.ieee.org/author/37323338000), [Patrick Haffner](https://ieeexplore.ieee.org/author/37320701100)  

## 0. datalodaer.py   

```python
import torch
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
from torch.utils.data import DataLoader

import numpy as np 

def load_dataset():

    # Basic transform for CIFAR-10 dataset
    basic_transform = transforms.Compose([
        transforms.Resize((32, 32)),  
        transforms.ToTensor()
    ])

    train_set = torchvision.datasets.CIFAR10(root='./cifar10', 
                                             train=True, download=True, 
                                             transform=basic_transform)
    test_set = torchvision.datasets.CIFAR10(root='./cifar10', 
                                            train=False, download=True, 
                                            transform=basic_transform)

    # Calculate mean/standard deviation per RGB channel
    train_meanRGB = [np.mean(x.numpy(), axis=(1,2)) for x, _ in train_set]
    train_stdRGB = [np.std(x.numpy(), axis=(1,2)) for x, _ in train_set]
    train_meanR = np.mean([m[0] for m in train_meanRGB])
    train_meanG = np.mean([m[1] for m in train_meanRGB])
    train_meanB = np.mean([m[2] for m in train_meanRGB])
    train_stdR = np.mean([s[0] for s in train_stdRGB])
    train_stdG = np.mean([s[1] for s in train_stdRGB])
    train_stdB = np.mean([s[2] for s in train_stdRGB])

    # Normaize for RGB 3channel
    normalize_transform = transforms.Normalize(
        mean=[train_meanR, train_meanG, train_meanB],
        std=[ train_stdR,  train_stdG,  train_stdB]
    )

    train_transformer = transforms.Compose([
        transforms.Resize((32, 32)),    
        transforms.ToTensor(),
        normalize_transform
    ])
    test_transformer = train_transformer

    train_set.transform = train_transformer
    test_set.transform = test_transformer

    batch_size = 128
    trainloader = DataLoader(train_set, batch_size=batch_size, 
                             shuffle=True,  num_workers=2)
    testloader  = DataLoader(test_set,  batch_size=batch_size, 
                             shuffle=False, num_workers=2)

    return trainloader, testloader
```

&nbsp;

## 1. model.py   

```python
import torch.nn as nn

class LeNet_5(nn.Module):
    def __init__(self):
        super(LeNet_5,self).__init__()

        # LeNet-5 architecture
        # Input: 32x32x3 (CIFAR-10 images)
        self.c1 = nn.Sequential(
            nn.Conv2d(3, 6, 5, 1),      
            nn.ReLU()
        )
        self.s2 = nn.AvgPool2d(2, 2)
        self.c3 = nn.Sequential(
            nn.Conv2d(6, 16, 5, 1),
            nn.ReLU()
        )
        self.s4 = nn.AvgPool2d(2, 2)

        self.c5 = nn.Sequential(
            nn.Conv2d(16, 120, 5, 1),
            nn.ReLU()
        )

        self.fc1 = nn.Sequential(
            nn.Flatten(),
            nn.Linear(120, 84),
            nn.ReLU(),
        )

        self.fc2 = nn.Sequential(
            nn.Linear(84, 10)
        )

    def forward(self, x):
        c1 = self.c1(x)      
        s2 = self.s2(c1)     
        c3 = self.c3(s2)    
        s4 = self.s4(c3)    
        c5 = self.c5(s4)    
        c5 = c5.view(c5.size(0), -1)  
        fc1 = self.fc1(c5)   
        fc2 = self.fc2(fc1)  
        return fc2
```

&nbsp;

## 2. train.py

```python
import numpy as np 
import torch
from torch import nn
from torch.nn import functional as F
from torch.utils.tensorboard import SummaryWriter

from model import LeNet_5
from dataloader import load_dataset
from tqdm import tqdm

def train(model, device, train_loader, optimizer, epoch):
    model.train()
    for batch_idx, (data,target) in enumerate(train_loader):
        target = target.type(torch.LongTensor)
        data, target = data.to(device), target.to(device)
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        if batch_idx % 30 == 0:
            print(f"{batch_idx*len(data)}/{len(train_loader.dataset)}")

def test(model, device, test_loader):
    model.eval()
    test_loss = 0
    correct = 0
    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)
            output = model(data)
            test_loss += criterion(output, target, reduction='mean').item()
            writer.add_scalar("Test Loss", test_loss, epoch)
            pred = output.argmax(1)
            correct += float((pred == target).sum())
            writer.add_scalar("Test Accuracy", correct, epoch)
            
        test_loss /= len(test_loader.dataset)
        correct /= len(test_loader.dataset)
        return test_loss, correct
        writer.close()

if __name__ == "__main__":

    num_epochs = 20
    learning_rate = 0.0001

    use_cuda = torch.cuda.is_available()
    print("use_cuda : ", use_cuda)
    device = torch.device("cuda:0" if use_cuda else "cpu")

    trainloader, testloader = load_dataset()

    model = LeNet_5().to(device)
    criterion = F.cross_entropy
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

    writer = SummaryWriter("./googlenet/tensorboard") 

    for epoch in tqdm(range(1, num_epochs + 1)):
        train(model, device, trainloader, optimizer, epoch)
        test_loss, test_accuracy = test(model, device, testloader)
        writer.add_scalar("Test Loss", test_loss, epoch)
        writer.add_scalar("Test Accuracy", test_accuracy, epoch)
        print(f"Processing Result = Epoch : {epoch}   Loss : {test_loss}   Accuracy : {test_accuracy}")
        writer.close()

                                 
    print(f"Result of LeNet-5 = Epoch : {epoch}   Loss : {test_loss}   Accuracy : {test_accuracy}")
```

**학습 결과**   
use_cuda :  True   
0%|          | 0/20 [00:00<?, ?it/s]0/50000    
3840/50000   
7680/50000  
11520/50000  
15360/50000  
19200/50000  
...  
42240/50000  
46080/50000  
31200/50000  
100%|██████████| 20/20 [05:07<00:00, 15.39s/it]Processing Result = Epoch : 20     Loss : 0.010388989973068237   Accuracy : 0.5314    
Result of LeNet-5 = Epoch : 20   Loss : 0.010388989973068237   Accuracy : 0.5314     
{: .notice}

&nbsp;


