---
layout : single
title: "[LeNet] LeNet-5 Paper Review"
categories: 
  - Classification Model 
toc: true
toc_sticky: true
use_math: true
---

Gradient-based learning applied to document recognition   

[참고 논문 링크](https://ieeexplore.ieee.org/document/726791)  

- [Proceedings of the IEEE](https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=5)   
- 4 August 2002
- [Y. Lecun](https://ieeexplore.ieee.org/author/37282875900), [Léon Bottou](https://ieeexplore.ieee.org/author/37282877000), [Yoshua Bengio](https://ieeexplore.ieee.org/author/37323338000), [Patrick Haffner](https://ieeexplore.ieee.org/author/37320701100)  


## 0. Classification Before LeNet   

&nbsp;

<div align="center">
  <img src="/assets/images/Net/20.png" width="40%" height="40%" alt=""/>
  <p><em></em></p>
</div>

&nbsp;

- **기존의 Classification 방식**   
  - 이전에는 패턴을 수식적으로 확인하여 이를 Classification module에 입력으로 넣어 Classfication을 진행함   
  - 이는 다음과 같은 과정을 거침   
    - 입력 이미지가 주어지면 해당 입력에 대해 수학적인 방식으로 입력 이미지의 특징(Feature)들을 추출   
    - 해당 feature들을 기반으로 적절한 feature들을 선별해서 해당 feature들의 vec과 같은 추가적인 정보를 얻어냄   
    - 최종적으로 이러한 정보들을 활용해 사물을 인식하는 과정을 거침   

&nbsp;

- **해당 방식의 한계**   
  - feature 추출에 많은 사전 지식이 포함되어 있어야 함   
  - feature 추출 과정에서 어떤 방식을 차용하는지에 따라 성능의 편차가 큼   
  - 새로운 문제(새로운 feature가 추가적으로 요구되거나 기존과는 다른 패턴을 보이는 경우)에는 시스템을 재구축해야함   

&nbsp;

## 1. LeNet-5   

&nbsp;

- **About LeNet**   
  - 더 나은 패턴 인식 시스템을 구축하기 위해 차용된 방식이 바로 **CNN(Convolution Neural Network)**를 활용하는 **LeNet-5**   
  - CNN은 기존 방식과는 달리 2D 이미지의 일정한 Local 패턴을 이용하는 특수한 구조  
    - 이를 이용한 다중 신경망 네트워크는 복잡/고차원/비선형 mapping을 여러 class를 맞춰 조합함으로써 오차를 계산해 경사 하강법을 통해 학습    
  - LeNet-5 이후의 모델에서 Feature 추출 작업은 CNN, Classifier module은 FC Layer를 통해 대체됨    

&nbsp;

## 2. LeNet-5 Architecture  

&nbsp;

<div align="center">
  <img src="/assets/images/Net/21.png" width="70%" height="70%" alt=""/>
  <p><em></em></p>
</div>

&nbsp;

- **LeNet-5 구조**   
  - 입력층을 제외한 7개의 Layer로 구성   
  - 입력 이미지는 32x32로 28x28 space에 문자의 정보가 추가되어 있음    
  - Layer 정보  
    - Cx : Convolution Layer  
    - Sx : Sub-Sampling Layer   
    - Fx : Fully connected Layer   
    - x : Layer Index   

&nbsp;

- **C1 Layer**   
  - 6개의 Feature Map을 가지고 있는 Conv Layer   
  - 각각의 Feature map에 있는 유닛들은 입력에 대해서 5x5 size의 kernel과 연결되어 Conv 연산을 수행   
  - 출력의 크기는 28x28x6   

&nbsp;

- **S2 Layer**   
  - 6개의 Feature Map을 가지고 있는 Average Pooling Layer  
  - 각각의 feature들은 대응되는 입력 채널에 대해서 2x2 필터를 거쳐 평균값을 추출, 1x1의 pixel size로 변환됨, 그 결과 C1 대비 절반의 size를 지님 
  - 출력의 크기는 14x14x6      

&nbsp;

<div align="center">
  <img src="/assets/images/Net/22.png" width="50%" height="50%" alt=""/>
  <p><em></em></p>
</div>

&nbsp;

- **C3 Layer**   
  - 16개의 feature map을 가지고 있는 Conv Layer   
  - 각각의 feature map들은 S2 feature map의 일부와 연결되어 5x5 kernel을 거쳐 Conv 연산을 수행   
  - 본 논문에서는 각각의 feature map이 입력으로 가져오는 채널들이 달랐지만, 코드 구현에서는 간단하게 모든 채널을 입력으로 삼는다고 가정   
  - 출력의 크기는 10x10x16    

&nbsp;

- **S4 Layer**  
  - 16개의 Feature map을 가지고 있는 Average pooling Layer   
  - 동작 방식은 S2와 동일   
  - 출력의 크기는 5x5x16   

&nbsp;

- **C5 Layer**   
  - 120개의 Feature map을 가지고 있는 Conv Layer   
  - 각각의 feature map들은 S4의 출력을 입력으로 받으며, 5x5 kernel고 함께 Conv 연산 수행   
  - 출력의 크기는 1x1x120    

&nbsp;

- **F6 Layer**   
  - 84개의 Feature map을 가지고 있는 FC Layer   
  - 해당 Layer의 결과에 대해 Softmax를 적용하여 최종적인 Classification을 수행   
  - 출력의 크기는 1x1x84   

&nbsp;



