---
layout : single
title: "[InceptionNet] InceptionNet V1. GoogLeNet Paper Review"
categories: 
  - Classification Model 
toc: true
toc_sticky: true
use_math: true
---

Going Deeper with Convolutions

[참고 논문 링크](https://arxiv.org/abs/1409.4842)  

- [CVPR](https://cvpr.thecvf.com/)   
- 17 September 2014 
- [Christian Szegedy](https://arxiv.org/search/cs?searchtype=author&query=Szegedy,+C), [Wei Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+W), [Yangqing Jia](https://arxiv.org/search/cs?searchtype=author&query=Jia,+Y), [Pierre Sermanet](https://arxiv.org/search/cs?searchtype=author&query=Sermanet,+P), [Scott Reed](https://arxiv.org/search/cs?searchtype=author&query=Reed,+S), [Dragomir Anguelo](https://arxiv.org/search/cs?searchtype=author&query=Anguelov,+D), [Dumitru Erhan](https://arxiv.org/search/cs?searchtype=author&query=Erhan,+D), [Vincent Vanhoucke](https://arxiv.org/search/cs?searchtype=author&query=Vanhoucke,+V), [Andrew Rabinovich](https://arxiv.org/search/cs?searchtype=author&query=Rabinovich,+A)   

## 0. About GoogLeNet   

&nbsp;

- **GoogLeNet**  
  - 네트워크의 Depth와 Width를 늘리면서도 내부적으로 Inception module을 활용해 computational efficiency를 확보한 모델    
  - 기존 VGGNet이 Deep Network로 AlexNet보다 높은 성능을 얻었지만, 파라미터 측면에서 그렇게 효율적이지 못한 부분을 보완하기 위해 만들어짐   

&nbsp;

## 1. CNN Architecture & GoogLeNet    

&nbsp;

- **Deep Network의 문제점**   
  - 2010년대의 CNN 아키텍쳐를 활용해 높은 이미지 인식 능력을 선보인 모델은 **AlexNet(2012) → VGGNet(2014) → GoogLeNet(2014) → ResNet(2015) → ...** 순으로 계보가 이어짐   
  - 해당 모델들은 네트워크의 Depth와 Width를 확장하면서 성능 향상을 꾀했지만, 다음과 같은 이슈들이 발생   
    - 많은 파라미터들이 있지만, 이를 학습시킬 충분한 데이터가 없다면 Overfitting이 발생함   
    - 연산 리소스는 제한적이므로 cost가 많이 발생하거나 낭비될 수 있음     

&nbsp;

- **GoogLeNet의 취지**   
  - 상기한 문제점들을 해결하기 위해 GoogLeNet에서는 FC Layer의 뉴련 수를 줄이거나, Convolution layer의 내부 또한 줄여 상대적으로 Sparse한 Network를 만들고자 함   
  - 결과적으로 GoogLeNet은 AlexNet 대비 파라미터 수가 12배 더 적지만 높은 성능을 보이며 ILSVRC 2014에서 classification과 detection track에서 SOTA를 달성    

&nbsp;

## 2. Inception   

&nbsp;

<div align="center">
  <img src="/assets/images/Net/7.png" width="80%" height="80%" alt=""/>
  <p><em>GoogLeNet Architecture</em></p>
</div>

&nbsp;

- **GoogLeNet 아키텍쳐**   
  - GoogLeNet 성능의 핵심은 **Inception 모듈**에 기인하지만, 이를 보기전 아키텍쳐를 확인하면 위 자료와 같음   
  - 왼쪽에서 출발하여 오른쪽으로 갈수록 점점 깊어지는 해당 구조에서 Inception 모듈은 GoogLeNet 네트워크에서 사용되는 부분 네트워크에 해당됨   

&nbsp;

<div align="center">
  <img src="/assets/images/Net/8.png" width="70%" height="70%" alt=""/>
  <p><em>Two types of Inception module</em></p>
</div>

&nbsp;

- **Inception module**   
  - 상기 자료는 Inception module의 구조를 도식화한 것으로 두 가지 버전이 존재   
  - 두 버전 모두 이미지 feature을 효율적으로 추출하기 위해 공통적으로 1x1, 3x3, 5x5 kernel size를 갖는 convolution 연산을 수행    
  - 이미지의 다양한 영역을 볼 수 있도록 서로 다른 크기의 kernel을 사용함으로써 앙상블하는 효과를 가져와 모델의 성능이 향상됨    
  - **홀수 size kernel**   
    - kernel size를 홀수로만 지정한 이유는 필요성에 의한 것이라기보다는 편의성을 위함  
    - 만약 짝수의 kernel size를 갖게 된다면 patch의 중간을 어디로 두어야 할지 결정해야하기에 번거로워지는데, 이를 **PAtch-alignment** 이슈라고 함   

&nbsp;

<div align="center">
  <img src="/assets/images/Net/9.png" width="60%" height="60%" alt=""/>
  <p><em>Naive Inception module</em></p>
</div>

&nbsp;

- **Naive Inception module**   
  - naive inception 모듈의 경우, 1x1, 3x3, 5x5 convolution 연산과 3x3 max pooling 연산을 병렬 수행한 후, concatenation을 통해 결과를 합쳐주는 구조로 구성되어 있음   
  - 다만, 동작이 잘 수행되지 않는데 원인은 다음고 같음   
    - convolution 결과와 max pooling 결과를 convatenation하면 기존보다 dimension이 늘어나는 문제점이 발생하기 때문   
    - 정확히는 max pooling 연산의 경우, 채널의 수가 그대로 보존되지만, convolution 연산에 의해 더해진 채널로 인해 연산 부하가 늘어나기 때문   

&nbsp;

<div align="center">
  <img src="/assets/images/Net/1.gif" width="40%" height="40%" alt=""/>
  <p><em>Dimension reduction Inception module<br>1x1 convolution</em></p>
</div>

&nbsp;

- **Inception module with Dimension reduction**  
  - naive version에서 ouput channel의 size가 증가하는 문제를 해결하기 위해 제시된 방식으로 output channel을 줄이는 기능을 추가로 구현함    
    - 실제로 연산 효율성이 뛰어나기 때문에 실제 아키텍쳐에서도 해당 모듈이 사용됨  
  - **1x1 convolution**   
    - 1x1 kernel size를 지닌 convolution 연산을 통해 channel size를 축소시켜 feature map size를 동일하게 유지함    
    - 또한 1x1 kernel을 몇개를 해주는냐에 따라 feature map의 channel size를 조절할 수 있음   
      - 이를 이용하면 Input dimension보다 1x1 filter 개수를 적게 해준다면 Dimension reduction을 통해 핵심적인 정보만 추출할 수 있게 됨   

&nbsp;

## 3. Global Average Pooling(GAP)   

&nbsp;

- **Global Average Pooling**   
  - GoogLeNet 아키텍처에선 Golbal Average Pooling 개념을 도입하여 사용   
  - 이는 기존 CNN + FC Layer 구조에서 FC Layer를 대체하기 위한 목적으로 Conv 연산을 통해 만들어진 feature map을 FC Layer에 넣고 최종적으로 분류하는 과정에서 공간정보가 손실되기 때문    
  - GAP는 feature map의 평균 값을 산출해 직접 Softmax Layer에 입력하는 방식으로, 이를 통해 공간 정보가 손실되지 않을 뿐만 아니라 FC Layer에 의해 Parameter를 최적화하는 과정이 생략되기 때문에 연산이 효율적임    

&nbsp;

## 4. Auxiliary Classification    

&nbsp;

<div align="center">
  <img src="/assets/images/Net/10.png" width="60%" height="60%" alt=""/>
  <p><em>Auxiliary Classification</em></p>
</div>

&nbsp;

- **Auxiliary Classification**   
  - Auxiliary는 '보조'를 뜻하는 단어이며, Auxiliary Classification은 최종 classification 결과를 보족하기 위해 네트워크 곳곳에 보조적인 classifier를 삽입하여 중간 결과 값을 추출하는 기법임(위 자료에서는 노란색 box열에 해당됨)   
  - 이는 네트워크가 깊어지면서 발생하는 Vanishing Gradient 문제를 해결하기 위함   
    - 네트워크가 깊어지면 loss에 대한 역전파 효과가 감소되기 때문    
  - 다만, Inception module version이 늘어날수록 Auxiliary Classifier를 줄여나갔고 Inception v4에서는 완전히 제외됨   
    - 이는 중간에 있는 layer들은 역전파를 통해 학습이 적절히 이루어졌지만, 최종 classification layer에서는 학습이 잘 이루어지지 못해 최적의 feature가 뽑히지 않기 때문   

&nbsp;

