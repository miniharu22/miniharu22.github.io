---
layout : single
title: "[Learning] Self-Supervised Learning"
categories: 
  - Deep Learning Basic
toc: true
toc_sticky: true
use_math: true
---

자기 지도 학습(Self-Supervised Learing)에 대해서 정리  

## 0. About Self-Supervised Learning

- **Self-Supervised Learing**  
  - 기존 지도 학습은 label data가 많아야 학습이 잘됨   
    - 하지만, label을 만드는 cost가 너무 큰 탓에 실용성이 떨어짐  
  - 자기 지도 학습(Self-Supervised Learning)은 진짜 풀려고 했던 문제가 아닌 **가짜 문제(Pretext Task)**를 새롭게 정의해서 **먼저 풀어봄(Pre-training)**  
    - 모델이 문제를 직접 만들어 풀어봄으로써 학습의 완성도를 올리는 기법    

&nbsp;

- **자기 지도 학습 과정**  
  - Pretext task(가짜 문제)를 학습해서 Pre-training 수행  
  - Downstream task(진짜 문제)를 풀기위해 Transfer training 수행  
    - 다만, Pretext task와 Downstream task는 다르기 때문에 Transfet training 수행 시에는 인공 신경망의 마지막 Layer를 수정해줘야 함  

&nbsp;

## 1. Contrastive Learning  

&nbsp;

<div align="left">
  <img src="/assets/images/DL/3.jpg" width="40%" height="40%" alt=""/>
  <p><em></em></p>
</div>

- **Contrastive Learning**
  - 데이터를 쌍(Pair)으로 비교하여, Positive pair는 임베딩 공간에서 서로 **가깝게**, Negative pair는 서로 **멀어지게** 학습함
  - 이때 Positive/Negative 쌍은 **레이블 없이** 데이터 자체로부터 정의되기 때문에 **자기지도학습(Self-Supervised Learning)** 에 해당함
  - 즉, 데이터 간 **유사도(Similarity)** 를 기준으로 **pre-training**을 수행하고,
    이를 기반으로 downstream task (분류, 검색 등)의 성능을 향상시킬 수 있음

&nbsp;

## 2. Contrastive Learning with MNIST Dataset
### 2-1. Download Dataset & Preprocessing

```python
# Download & Preprocess Dataset 
mnist= fetch_openml('mnist_784')

# Set GPU Device
device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')

# Set the first 60,000 out of 70,000 as Train data
X_train = torch.tensor(np.array(mnist.data)).float().reshape(-1, 1, 28, 28)[:60000].to(device)
Y_train = torch.tensor(np.array(list(map(np.int_, mnist.target))))[:60000].to(device)

# Set the last 10,000 out of 70,000 as Test data
X_test = torch.tensor(np.array(mnist.data)).float().reshape(-1, 1 ,28, 28)[60000:].to(device)
Y_test = torch.tensor(np.array(list(map(np.int_, mnist.target))))[60000:].to(device)

print(X_train.shape) # torch.Size([60000, 1, 28, 28])
print(Y_train.shape) # torch.Size([60000])

print(X_test.shape) # torch.Size([10000, 1, 28, 28])
print(Y_test.shape) # torch.Size([10000])
```

**출력 결과**  
torch.Size([60000, 1, 28, 28])  
torch.Size([60000])  
torch.Size([10000, 1, 28, 28])  
torch.Size([10000])  
{: .notice}

- `scikit-learn`을 이용하여 Dataset을 불러오고 직접 tensor로 변환  
- labeling은 데이터 순서와 상관없이 뒤섞여 있다는 점을 고려, 앞 6만개를 학습용, 뒤 1만개를 테스트용으로 split  
- Image pixel 수와 CNN Input 형태를 고려하여 각 이미지를 미리 1x28x28 차원으로 변환  


&nbsp;

### 2-2. Data Augmentation  

```python
# Data Augmentation
def cutout_and_rotate(image):
    image = image.clone().detach() 
    x_start = np.random.randint(20)     # Cut- out x-axis position to start (1 of 0-19)
    y_start = np.random.randint(20)     # Cut- out y-axis position to start (1 of 0-19)

    # Gray marking on the corresponding part
    image[..., x_start:x_start+9, y_start:y_start+9] = 255/2
    # 90 degree rotation based on the last two axis
    return torch.rot90(image, 1, [-2, -1])

# Test Case fot Data Augmentation
import matplotlib.pyplot as plt
from matplotlib.pyplot import style

# Specify whit background & its size  
style.use('default')
figure = plt.figure()
figure.set_size_inches(4, 2)

# Set the style for black & white print
style.use('grayscale')

# 1x2 size grid setting
axes = []
for i in range(1,3):
    axes.append(figure.add_subplot(1, 2, i))

# Visulization of the original Image
# Visulization of the image performed by augmentation fot the first image
img_example = X_train[0].clone().detach().cpu()
original = np.array(img_example).reshape(-1, 28).astype(int)
aug_img = np.array(cutout_and_rotate(img_example)).reshape(-1, 28).astype(int)

axes[0].matshow(original)
axes[1].matshow(aug_img)

axes[0].set_axis_off()
axes[0].set_title('original')
axes[1].set_axis_off() 
axes[1].set_title('augmentation')

plt.show()
```

<div align="left">
    <strong>출력 결과</strong>
  <img src="/assets/images/DL/3.png" width="50%" height="50%" alt=""/>
  <p><em></em></p>
</div>
{: .notice} 

- **Data Augmentation 구현**  
  - 랜덤으로 10x10 pixel 부위를 골라 회색으로 marking  
  - marking 이후, 왼쪽으로 90도 회전  

&nbsp;

### 2-3. CNN Model Structure  

```python
# Implementing CNN Model Structure
from torch import nn
import torch.nn.functional as F

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5, stride= 1)
        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5, stride= 1)
        self.fc = nn.Linear(4 * 4 * 20, 100)

    def forward(self, x):
        # (batch, 1, 28, 28) -> (batch, 10, 24, 24)
        x = F.relu(self.conv1(x)) 
        # (batch, 10, 24, 24) -> (batch, 10, 12, 12)
        x = F.max_pool2d(x, kernel_size=2, stride=2) 
        # (batch, 10, 12, 12) -> (batch, 20, 8, 8)
        x = F.relu(self.conv2(x)) 
        # (batch, 20, 8, 8) -> (batch, 20, 4, 4)
        x = F.max_pool2d(x, kernel_size=2, stride=2) 
        # (batch, 20, 4, 4) -> (batch, 320)
        x = x.view(-1, 4 * 4 * 20) 
        # (batch, 320) -> (batch, 100)
        x = F.relu(self.fc(x)) 
        # (batch, 100)
        return x 
```

- 여기서는 Convolution layer가 2개만 존재하는 간단한 CNN 구조를 가정  
- 각 Layer를 거칠 때마다 변화하는 shape는 주석에 포함  
  - 각 이미지의 output vector의 차원은 100차원으로 가정  

&nbsp;

### 2-4. Loss Function

```python
# Implementing Loss Function
class SimCLR_Loss(nn.Module):
    def __init__(self, batch_size, temperature):
        super().__init__()
        self.batch_size = batch_size
        self.temperature = temperature

        self.mask = self.mask_correlated_samples(batch_size)
        self.criterion = nn.CrossEntropyLoss(reduction="sum")
        self.similarity_f = nn.CosineSimilarity(dim=2)

    # masking matrix to import only the internal sum
        # between the negative samples of the loss denominator part
    def mask_correlated_samples(self, batch_size):
        N = 2 * batch_size
        mask = torch.ones((N, N), dtype=bool)
        mask = mask.fill_diagonal_(0)
        
        for i in range(batch_size):
            mask[i, batch_size + i] = 0
            mask[batch_size + i, i] = 0
        return mask

    def forward(self, z_i, z_j):

        N = 2 * self.batch_size

        z = torch.cat((z_i, z_j), dim=0)

        sim = self.similarity_f(z.unsqueeze(1), z.unsqueeze(0)) / self.temperature

        # The source of the loss molecule part
        # The part to get the internal sum between the augmentation images
        sim_i_j = torch.diag(sim, self.batch_size)
        sim_j_i = torch.diag(sim, -self.batch_size)
        
        positive_samples = torch.cat((sim_i_j, sim_j_i), dim=0).reshape(N, 1)
        negative_samples = sim[self.mask].reshape(N, -1)
        
        labels = torch.from_numpy(np.array([0]*N)).reshape(-1).to(positive_samples.device).long()
        
        logits = torch.cat((positive_samples, negative_samples), dim=1)
        loss = self.criterion(logits, labels)
        loss /= N
        
        return loss
```

- Contrastive Loss 계산  
  - N개의 이미지로 구성된 Batch의 각 이미지에서 augmentation된 N개의 이미지를 합쳐, 총 2N개의 이미지를 최종 Batch로 구성  
  - Image Pair 처리  
    - 해당 이미지 & augmentation 이미지 Pair -> Positive Data(분자 부분)   
    - 해당 이미지 & 나머지 이미지의 2N-2개 Pair -> Negative Data(분모 부분)  
  - 이후, 각 pair를 아래 식에 대입하여 Contrastive loss 계산  
  
&nbsp;

<div align= 'center'>
    $$\ell_{i,j} = -\log \frac{\exp(\mathrm{sim}(z_i, z_j)/\tau)}{\sum_{k=1}^{2N} \mathbb{1}_{[k \neq i]} \exp(\mathrm{sim}(z_i, z_k)/\tau)}$$
</div>

&nbsp;

### 2-5. Pre-Training

```python
# Pre-train
from torch.utils.data import TensorDataset
from torch.utils.data import DataLoader
from tqdm.notebook import tqdm

# Augmentation for each X_train data
X_train_aug = cutout_and_rotate(X_train) 
# Declare to GPU for Learning
X_train_aug = X_train_aug.to(device) 

# Pair with Augmentation data
dataset = TensorDataset(X_train, X_train_aug) 
batch_size = 32

dataloader = DataLoader(
            dataset,
            batch_size = batch_size)

# Declare Model variable
model = CNN() 
# Declare Loss Function
loss_func = SimCLR_Loss(batch_size, temperature = 0.5) 

# training
epochs = 10
model.to(device)
model.train()

optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)

for i in range(1, epochs + 1):
    total_loss = 0
    for data in tqdm(dataloader):
        origin_vec = model(data[0])
        aug_vec = model(data[1])

        loss = loss_func(origin_vec, aug_vec)
        total_loss += loss.item()

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print('Epoch : %d, Avg Loss : %.4f'%(i, total_loss / len(dataloader)))
```

<div align="left">
    <strong>Train Results</strong>
  <img src="/assets/images/DL/4.png" width="50%" height="50%" alt=""/>
  <p><em></em></p>
</div>
{: .notice} 


&nbsp;

### 2-6. Downstream Model Training for Classification

```python
# Downstream model for Classification
class CNN_classifier(nn.Module):
    def __init__(self, model):
        super().__init__()
        # Load model trained with Constrastive Learning
        self.CNN = model 
        # Projection by the number of class dimensions
        self.mlp = nn.Linear(100, 10) 

    def forward(self, x):
        x = self.CNN(x) # Convert to (batch, 100)
        x = self.mlp(x) # Convert to (batch, 10)
        return x # (batch, 10)

# Pair with Data & Lable
class_dataset = TensorDataset(X_train, Y_train)
batch_size = 32

class_dataloader = DataLoader(
        class_dataset,
        batch_size = batch_size)


# Classification Downstream model Training
classifier = CNN_classifier(model).to(device)
classifier_loss = nn.CrossEntropyLoss()

optimizer = torch.optim.Adam(classifier.parameters(), lr= 1e-4)

for i in range(1, epochs + 1):
    correct = 0
    for data in tqdm(class_dataloader):
        logits = classifier(data[0])

        loss = classifier_loss(logits, data[1].long())

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        # Accumulate number of correct answers for Accuracy calculation
        correct += torch.sum(torch.argmax(logits, 1) == data[1]).item() 

    print('Epoch : %d, Train Accuracy : %.2f%%'%(i, correct * 100 / len(X_train)))
```

<div align="left">
    <strong>Train Results</strong>
  <img src="/assets/images/DL/5.png" width="50%" height="50%" alt=""/>
  <p><em></em></p>
</div>
{: .notice} 

- 위에서 학습된 CNN Model에 class 개수만큼의 차원으로 projection을 진행하는 MLP Layer를 장착하여 최종 class 분류를 위한 Downstream model을 선언  
  - 여기서는 단일 MLP Layer만을 이용하여 Projection하는 상황을 가정  
- 학습의 경우에는 이제 agumentation된 이미지들이 필요하지 않기 때문에, 이미지와 label간의 pair를 이루어 dataloader를 선언해줘야 함  
- epoch가 거듭될수록 train accuracy가 꾸준히 상승하는 것을 확인 가능  

&nbsp;

### 2-7. Test set Verification

```python
# Verification with Test Data
# pair with Test data & Label
test_dataset = TensorDataset(X_test, Y_test) 
batch_size = 32

test_dataloader = DataLoader(
            test_dataset,
            batch_size = batch_size)

# Convert to Test mode
classifier.eval() 

correct = 0
for data in tqdm(test_dataloader):

    logits = classifier(data[0])
    # Accumulate number of correct answers for Accuracy calculation
    correct += torch.sum(torch.argmax(logits, 1) == data[1]).item() 

print('Test Accuracy : %.2f%%'%(correct * 100 / len(X_test)))
```

<div align="left">
    <strong>Test Results</strong>
  <img src="/assets/images/DL/6.png" width="50%" height="50%" alt=""/>
  <p><em></em></p>
</div>
{: .notice} 

- 약 98.31%의 Test Accuracy가 산출되는 것으로 보아 학습의 정확도가 높은 것을 알 수 있음  

&nbsp;